# -*- coding: utf-8 -*-
"""Transfer Learning Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mGWdHKpfcOPDUQoNE-MqVuEc64EHk10S

# Loading covid dataset
"""

import json,urllib.request
import pandas as pd

data = urllib.request.urlopen("https://raw.githubusercontent.com/ieee8023/covid-chestxray-dataset/master/annotations/imageannotation_ai_lung_bounding_boxes.json").read()
output = json.loads(data)
filenames =  [ x['file_name'] for x in output['images']]
labels = [ x['metadata']['finding'] for x in output['images']]
view = [ x['metadata']['view'] for x in output['images']]
modality = [ x['metadata']['modality'] for x in output['images']]
#COVID pandas dataset
data = {'Finding Labels': labels, 'Image Index':filenames, 'View' : view, 'Modality': modality}
covids = pd.DataFrame.from_dict(data)
covids = covids[lambda x : x['Finding Labels'] == 'COVID-19']
covids = covids[lambda x : x['View'] == 'PA' ]
covids = covids[lambda x : x['Modality'] == "X-ray"]
#and 
covids['Image Index'] = covids['Image Index'].apply(lambda x : '/content/Images/Covid/' + x)
covids.dropna(axis=1,inplace=True)
covids.head()

covids['Image Index'][0]

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# #DOWNLOAD COVID IMAGES
# base_url = 'https://raw.githubusercontent.com/ieee8023/covid-chestxray-dataset/master/images/'
# for filename in filenames:
#   url = base_url + filename
#   !wget $url -P /content/Images/Covid/

"""###extracting watermarks test 1"""

!mkdir /content/Images/watermarks

from skimage.segmentation import slic
from skimage.segmentation import mark_boundaries
from skimage.util import img_as_float
import matplotlib.pyplot as plt
import numpy as np
import argparse
import cv2

path = "/content/Images/watermarks"
img = covids['Image Index'].to_numpy()
img = img[9]

img_test = np.expand_dims(plt.imread(img),0)
plt.imshow(img_test[0])

"""#### Extracting watermarks"""

cvimg = cv2.imread(img)
mask = cv2.threshold(cvimg, 210, 255, cv2.THRESH_BINARY)[1][:,:,0]
dst = cv2.inpaint(cvimg, mask, 7, cv2.INPAINT_NS)
cv2.imwrite(path + img.split('/')[-1], dst)

after = np.expand_dims(plt.imread(path + img.split('/')[-1]),0)
#plt.imshow(after[0])
plt.imshow(mask, 'gray')

#found a threshold that finds all watermarks!
cvimg = cv2.imread(img,0)
th2 = cv2.adaptiveThreshold(cvimg,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,5,19)
plt.imshow(th2, 'gray')

"""#Cropping Covid Images"""

!mkdir /content/Images/Cropped/
import cv2

images = covids['Image Index'].to_numpy()
path = "/content/Images/Cropped/"

for img in images:
  cvimg = cv2.imread(img)
  xmargin = int(round(0.08*cvimg.shape[1]))
  ymargin = int(round(0.08*cvimg.shape[0]))
  crop_img = cvimg[ymargin:, xmargin:]
  cv2.imwrite(path + img.split('/')[-1], crop_img)

covids['Image Index'] = covids['Image Index'].apply(lambda x : x.replace('Covid','Cropped'))

"""Inpaiting of white text"""

!mkdir /content/Images/Filled

images = covids['Image Index'].to_numpy()
path = "/content/Images/Filled/"

for img in images:
  cvimg = cv2.imread(img)
  mask = cv2.threshold(cvimg, 210, 255, cv2.THRESH_BINARY)[1][:,:,0]
  dst = cv2.inpaint(cvimg, mask, 7, cv2.INPAINT_NS)
  cv2.imwrite(path + img.split('/')[-1], dst)

covids['Image Index'] = covids['Image Index'].apply(lambda x : x.replace('Cropped','Filled'))

"""# Augmentation of covid dataset



*   Flipping the image either horizontally or vertically
*   Rotating the image
*   Zooming in or out on the image
*   Varying the color on the image
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np
import keras
from keras.preprocessing.image import ImageDataGenerator
# %matplotlib inline

# plots images with labels 
def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):
    if type(ims[0]) is np.ndarray:
        ims = np.array(ims).astype(np.uint8)
        if (ims.shape[-1] != 3):
            ims = ims.transpose((0,2,3,1))
    f = plt.figure(figsize=figsize)
    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1
    for i in range(len(ims)):
        sp = f.add_subplot(rows, cols, i+1)
        sp.axis('Off')
        if titles is not None:
            sp.set_title(titles[i], fontsize=16)
        plt.imshow(ims[i], interpolation=None if interp else 'none')

gen = ImageDataGenerator(rotation_range=10,
                         rescale=1/255, 
                         width_shift_range=0.1, 
                         height_shift_range=0.1, 
                         shear_range=0.15, 
                         zoom_range=0.1, 
                         channel_shift_range=10., 
                         horizontal_flip=True)

img_test = np.expand_dims(plt.imread(covids['Image Index'][20]),0)
plt.imshow(img_test[0])

aug_iter = gen.flow(img_test)
aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(10)]
plots(aug_images, figsize=(20,7), rows=2)

"""# Loading "No Finding" Dataset"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install kaggle
# import json
# import zipfile
# import os
# !mkdir /root/.kaggle
# !echo '{"username":"boesingerl","key":"1f278ec8d4b16c055ed81dfc6d0c3b0f"}' > /root/.kaggle/kaggle.json
# !kaggle datasets download "nih-chest-xrays/sample"
# !unzip /content/sample.zip -d /content/nih

all_xray_df = pd.read_csv('/content/nih/sample_labels.csv')
all_xray_df.head()

#LOAD NIH DATASET AND MERGE WITH COVID
all_xray_df = pd.read_csv('/content/nih/sample_labels.csv')
all_xray_df = all_xray_df[all_xray_df['Finding Labels'] == "No Finding"][all_xray_df['View Position'] == "PA"][['Image Index', 'Finding Labels']]
all_xray_df['Image Index'] = all_xray_df['Image Index'].apply(lambda x : '/content/nih/sample/images/' + x)
all_xray_df = all_xray_df.sample(300)
second_sample = all_xray_df[100:]
all_xray_df = all_xray_df[:100]
merged = all_xray_df.append(covids)
merged = merged.sample(frac=1).reset_index(drop=True)
print(merged)

"""# Scale pictures and adding watermarks

### Showcase the model

#### Scaling Covid images
"""

# Scaling Covid images
gen = ImageDataGenerator()
covid_gen = gen.flow_from_dataframe(dataframe=covids,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=(224, 224),
                                     class_mode='categorical',
                                     batch_size=200)
X_covids, Y_covids = next(covid_gen)

ind = 62
img_scaled = X_covids[ind].astype(np.uint8)
gray = cv2.cvtColor(img_scaled, cv2.COLOR_BGR2GRAY)
plt.imshow(gray, 'gray')

"""#### Filter Watermarks"""

th2 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,3,19)
th2 = cv2.bitwise_not(th2)
plt.imshow(th2, 'gray')

"""#### Scaling "No finding" images"""

gen = ImageDataGenerator()
noFind_gen = gen.flow_from_dataframe(dataframe= all_xray_df,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=(224, 224),
                                     class_mode='categorical',
                                     batch_size=200)
X_batchNF, Y_batchNF = next(noFind_gen)

imgNF_scaled = X_batchNF[ind].astype(np.uint8)
grayNF = cv2.cvtColor(imgNF_scaled, cv2.COLOR_BGR2GRAY)
plt.imshow(imgNF_scaled)

"""#### Combining pictures"""

contours, hierarchy = cv2.findContours(th2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
cv2.drawContours(imgNF_scaled, contours, -1, (0,0,0), 1)
plt.imshow(imgNF_scaled, 'gray')

"""### Adding all watermarks from covids to No Find"""

# Scaling Covid images
gen = ImageDataGenerator()
covid_gen = gen.flow_from_dataframe(dataframe=covids,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=(224, 224),
                                     class_mode='categorical',
                                     batch_size=200)
X_covids, Y_covids = next(covid_gen)

noFind_gen = gen.flow_from_dataframe(dataframe= all_xray_df,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=(224, 224),
                                     class_mode='categorical',
                                     batch_size=200)
X_batchNF, Y_batchNF = next(noFind_gen)

!mkdir /content/Images/Watermarked/

path = "/content/Images/Watermarked/"
WM_Images = []
for i in range(0, len(X_covids)-1):
  #Change covid img to gray
  img_scaled = X_covids[i].astype(np.uint8)
  gray = cv2.cvtColor(img_scaled, cv2.COLOR_BGR2GRAY)
  
  #Filter Watermarks
  th2 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,3,19)
  th2 = cv2.bitwise_not(th2)
  
  #Change No Find img to gray
  imgNF_scaled = X_batchNF[i].astype(np.uint8)
  grayNF = cv2.cvtColor(imgNF_scaled, cv2.COLOR_BGR2GRAY)
  #Combining img and watermark
  contours, hierarchy = cv2.findContours(th2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
  cv2.drawContours(imgNF_scaled, contours, -1, (0,0,0), 1)
  plt.imsave(path + str(i) +".jpeg", imgNF_scaled)
  X_batchNF[i] = imgNF_scaled
  #cv2.imwrite(path + str(i) +".jpeg", imgNF_scaled)
  WM_Images.append(path + str(i) +".jpeg")

print(WM_Images)

index = 69 #good examples: 39 53 69
f, axarr = plt.subplots(1,2)
axarr[0].set_title('Covid')
axarr[0].imshow(X_covids[index].astype(np.uint8), 'gray')
axarr[1].set_title('No find')
axarr[1].imshow(X_batchNF[index].astype(np.uint8), 'gray')

#HAS TO BE RAN AFTER THE GENERATORS

#Flow using current array and create a data generator
non_covid_gen = core_idg.flow(X_batchNF, Y_batchNF, batch_size=(X_batchNF.shape[0]))

#Get X and Y from this generator
X_non_covid, Y_non_covid = next(non_covid_gen)

#Set the Y label to be forced as non covid
Y_non_covid = np.zeros((X_non_covid.shape[0],2))
Y_non_covid[:,0] = 1

##Same for covid data
covid_gen = core_idg.flow(X_covids, Y_covids, batch_size=(X_covids.shape[0]))

#Get X and Y from this generator
X_covid, Y_covid = next(covid_gen)

#Set the Y label
Y_covid =  np.zeros((X_covid.shape[0],2))
Y_covid[:,1] = 1
#Merge them

X = np.append(X_non_covid, X_covid, axis=0)
Y = np.append(Y_non_covid, Y_covid, axis=0)
print(Y.shape)
#Randomize order
ranX = np.arange(X.shape[0])
np.random.shuffle(ranX)
ranY = np.arange(Y.shape[0])
np.random.shuffle(ranY)
X = X[ranX]
Y = Y[ranY]

"""#### Test watermarks with Basic Model"""

from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Flatten, Dense

trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

model = Sequential()
model.add(Flatten())
model.add(Dense(64, activation="relu"))
model.add(Dense(2, activation="softmax"))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
H = model.fit(
	trainX, trainY,
  validation_data=(testX, testY),
	epochs=EPOCHS)

"""####Test Watermarks with more advanced model"""

from keras.applications import VGG16
from keras import Model
from keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split

def imagenet_model(lr=1e-3, epochs=25, dropout_rate=0.5,dense_nodes=64,base_model=VGG16):
	baseModel = base_model(weights="imagenet", include_top=False,
		input_tensor=Input(shape=(224, 224, 3)))

	for layer in baseModel.layers:
		layer.trainable = False

	headModel = baseModel.output
	headModel = AveragePooling2D(pool_size=(4, 4))(headModel)
	headModel = Flatten(name="flatten")(headModel)
	headModel = Dense(dense_nodes, activation="relu")(headModel)
	headModel = Dropout(dropout_rate)(headModel)
	headModel = Dense(2, activation="softmax")(headModel)
	model = Model(inputs=baseModel.input, outputs=headModel)
	opt = Adam(lr=lr, decay=lr / epochs)
	model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
	return model

	model = imagenet_model(dense_nodes=50)

trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

H = model.fit(
	trainX, trainY,
  validation_data=(testX, testY),
	epochs=10)

"""# Extracting Watermarks from covid data 2"""

!mkdir /content/Images/Watermarked/

!rm /content/Images/Watermarked/*

import numpy as np
import cv2
import skimage.measure
from skimage import morphology

path = "/content/Images/Watermarked/"
WM_Images = []
masks = []
for i in range(0, len(X_covids)-1):
#for i in range(38,39):
  #Change covid img to gray
  gray = X_covids[i].astype(np.uint8)
  
  #Filter Watermarks
  mask = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)[1]
  blur = cv2.GaussianBlur(mask,(11,11),0)
  #blur = np.where(blur > 20, 255,0)
  num_labels,labels,stats,centroids = cv2.connectedComponentsWithStats(blur, 4, cv2.CV_32S)
  for j in range(num_labels):
    if stats[j,cv2.CC_STAT_AREA] > 500 and stats[j,cv2.CC_STAT_AREA] < 30000 :
      mask = np.where(labels == j, 0, mask)

  binarized = np.where(mask > 20,1,0).astype(bool)
  processed = morphology.remove_small_objects(binarized, min_size=2, connectivity=3).astype(int)
  mask_x, mask_y = np.where(processed == 0)
  mask[mask_x,mask_y] = 0

  if(np.where(mask > 20)[0].size > 0.001*mask.size):
    cv2.imwrite(path + str(i) +".jpeg", mask)
    WM_Images.append(path + str(i) +".jpeg")
    masks.append(mask)

path = '/content/Images/WithWatermarks/'
watermarked_images = []
!mkdir $path
for i in range(len(WM_Images)):
  rgb_mask = gray_three = cv2.merge([mask,mask,mask])
  X_batchNF[i] = np.where(rgb_mask > 20, rgb_mask, X_batchNF[i])
  cv2.imwrite(path + str(i) +".jpeg", X_batchNF[i])
  watermarked_images.append(path + str(i) + ".jpeg")

import matplotlib.pyplot as plt
plt.imshow(X_batchNF[5].astype(np.uint8), 'gray')

!zip -r /content/ok.zip /content/Images/Watermarked/

"""#### Testing with Grad Cam"""

!mkdir /content/Images/Gradcams_WM

import cv2
from keras import backend as K

def get_class_activation_map(model,files,outpath='/content/Images/Gradcams') :
    for imgName in files:
      img = cv2.imread(imgName)
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      img = cv2.resize(img, (224, 224))
      img = np.expand_dims(img,axis=0)
      
      predict = model.predict(img)
      target_class = np.argmax(predict[0])
      last_conv = model.get_layer('block5_conv3')
      grads = K.gradients(model.output[:,target_class],last_conv.output)[0]
      pooled_grads = K.mean(grads,axis=(0,1,2))
      iterate = K.function([model.input],[pooled_grads,last_conv.output[0]])
      pooled_grads_value,conv_layer_output = iterate([img])
      
      for i in range(512):
          conv_layer_output[:,:,i] *= pooled_grads_value[i]
      
      heatmap = np.mean(conv_layer_output,axis=-1)
      
      for x in range(heatmap.shape[0]):
          for y in range(heatmap.shape[1]):
              heatmap[x,y] = np.max(heatmap[x,y],0)
      heatmap = np.maximum(heatmap,0)
      heatmap /= np.max(heatmap)
      plt.imshow(heatmap)
      img_gray = cv2.cvtColor(img[0], cv2.COLOR_BGR2GRAY)
      upsample = cv2.resize(heatmap, (224,224))
    
      output_path_gradcam =  outpath + '/'+ imgName.split('/')[-1]
      plt.imsave(output_path_gradcam,upsample * img_gray)

watermarked_images

get_class_activation_map(model, watermarked_images, outpath='/content/Images/Gradcams_WM/')

get_class_activation_map(model, WM_Images, outpath='/content/Images/Gradcams_WM/')

!zip -r /content/gradcams.zip /content/Images/Gradcams_WM

"""# Data generators"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
from glob import glob
# %matplotlib inline
import matplotlib.pyplot as plt

INIT_LR = 1e-3
EPOCHS = 25
BS = 8

from keras.preprocessing.image import ImageDataGenerator
import keras 
core_idg = ImageDataGenerator(preprocessing_function=keras.applications.vgg16.preprocess_input,
                              horizontal_flip = True, 
                              vertical_flip = False, 
                              height_shift_range= 0.1, 
                              width_shift_range=0.2, 
                              rotation_range=10, 
                              shear_range = 0.2,
                              fill_mode = 'nearest',
                              zoom_range=0.15)

IMAGENET_SIZE = (224, 224)
imagenet_gen = core_idg.flow_from_dataframe(dataframe=merged,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=IMAGENET_SIZE,
                                     class_mode='categorical',
                                     batch_size=200)
noncovid_gen = core_idg.flow_from_dataframe(dataframe=second_sample,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=IMAGENET_SIZE,
                                     class_mode='categorical',
                                     classes=imagenet_gen.class_indices,
                                     batch_size=200)

"""# Weights initialized on NIH (TODO)
In this section, we first train a network on the NIH chest lung dataset, in order to use transfer learning with this network

## Training a network on NIH dataset (INCOMPLETE)
"""

# Start with No finding vs Pneumonia classifier using NIH dataset
nih_df = pd.read_csv('/content/nih/sample_labels.csv')
nih_df.head()

data=nih_df.groupby('Finding Labels').agg('count').sort_values('Image Index',ascending=False)['Image Index']
#Select only images for which we have the most samples
finding_labels = list(data.head(5).index)
#Let's train on the first 5, for now just with the samples, later maybe with the full dataset

nih_df = nih_df[nih_df['Finding Labels'].isin(finding_labels)]
nih_df = nih_df[nih_df['View Position'] == 'PA']
nih_df['Image Index'] = nih_df['Image Index'].apply(lambda x : '/content/nih/sample/images/' + x)

#Sample
balanced_df=nih_df.groupby('Finding Labels',as_index = False,group_keys=False).apply(lambda s: s.sample(100,replace=True))

before_sampling = nih_df.groupby('Finding Labels').agg('count').sort_values('Image Index',ascending=False)['Image Index']
after_sampling = balanced_df.groupby('Finding Labels').agg('count').sort_values('Image Index',ascending=False)['Image Index']

print("BEFORE SAMPLING\n\n",before_sampling, "\n\nAFTER SAMPLING\n\n",after_sampling)

from sklearn.model_selection import train_test_split
IMAGENET_SIZE = (224, 224)
nih_gen = core_idg.flow_from_dataframe(dataframe=nih_df,
                                      x_col = 'Image Index',
                                      y_col = 'Finding Labels',
                                      target_size=IMAGENET_SIZE,
                                      class_mode='categorical',
                                      batch_size=balanced_df.shape[0])
X,Y = next(nih_gen)
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

from keras.applications import VGG16
from keras.layers import AveragePooling2D, Input
from keras.optimizers import Adam
from keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from keras.models import Model

baseModel = VGG16(weights="imagenet", include_top=False,
	input_tensor=Input(shape=(224, 224, 3)))
headModel = baseModel.output
headModel = AveragePooling2D(pool_size=(4, 4))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(64, activation="relu")(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(5, activation="softmax")(headModel)
model = Model(inputs=baseModel.input, outputs=headModel)

trainAug = ImageDataGenerator(
	rotation_range=15,
	fill_mode="nearest")

INIT_LR=1e-4
opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)
model.compile(loss="categorical_crossentropy", optimizer=opt,metrics=["categorical_accuracy"])

H = model.fit_generator(
	trainAug.flow(trainX, trainY, batch_size=BS),
	steps_per_epoch=len(trainX) // BS,
  validation_data=(testX, testY),
	validation_steps = len(testX) //BS,
	epochs=50)

from keras.metrics import categorical_accuracy
pred_Y = model.predict(testX, batch_size = 10, verbose = True)

"""Plotting losses"""

# Plot training & validation accuracy values
plt.plot(H.history['categorical_accuracy'])
plt.plot(H.history['val_categorical_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(H.history['loss'])
plt.plot(H.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""Pretty highly overfitting => need more data (use complete nih dataset and not only a sample of it)

# Training without transfer learning
"""

from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Flatten, Dense

X,Y = next(imagenet_gen)
print(len(X))
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

model = Sequential()
model.add(Flatten())
model.add(Dense(64, activation="relu"))
model.add(Dense(2, activation="softmax"))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
H = model.fit(
	trainX, trainY,
  validation_data=(testX, testY),
	epochs=EPOCHS)

# Plot training & validation accuracy values
plt.plot(H.history['categorical_accuracy'])
plt.plot(H.history['val_categorical_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(H.history['loss'])
plt.plot(H.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

val_loss, val_acc = model.evaluate(testX, testY)
print(val_loss, val_acc)

model.predict(test_x)

"""**This indecates that the network is overfitting**

# Weights initialized on ImageNet
In this section, we use a network pretrained on the ImageNet dataset for transfer learning.
Baseline : https://colab.research.google.com/github/HarshCasper/Brihaspati/blob/master/COVID-19/COVID19-XRay.ipynb#scrollTo=_Oc8hGXDIFDd

I would have preferred to use fit_generator rather than simple fit using a part of dataset, but it appears that grid search with sklearn is not doable otherwise

We use categorical crossentropy, as cases cannot be both covid and non-covid
"""

from keras.applications import VGG16
from keras import Model
from keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split

def imagenet_model(lr=1e-3, epochs=25, dropout_rate=0.5,dense_nodes=64,base_model=VGG16):
	baseModel = base_model(weights="imagenet", include_top=False,
		input_tensor=Input(shape=(224, 224, 3)))

	for layer in baseModel.layers:
		layer.trainable = False

	headModel = baseModel.output
	headModel = AveragePooling2D(pool_size=(4, 4))(headModel)
	headModel = Flatten(name="flatten")(headModel)
	headModel = Dense(dense_nodes, activation="relu")(headModel)
	headModel = Dropout(dropout_rate)(headModel)
	headModel = Dense(2, activation="softmax")(headModel)
	model = Model(inputs=baseModel.input, outputs=headModel)
	opt = Adam(lr=lr, decay=lr / epochs)
	model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
	return model

from keras.applications.vgg16 import preprocess_input

model = imagenet_model(dense_nodes=50)
X,Y = next(imagenet_gen)
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

H = model.fit(
	trainX, trainY,
  validation_data=(testX, testY),
	epochs=25)

validX,validY = next(noncovid_gen)
model.evaluate(validX,validY)

# Plot training & validation accuracy values
plt.plot(H.history['categorical_accuracy'])
plt.plot(H.history['val_categorical_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(H.history['loss'])
plt.plot(H.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

loss, accuracy = model.evaluate(testX, testY)
print(loss,accuracy)

"""## Hyper-parameter optimization with sklearn"""

from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV

model = KerasClassifier(build_fn=imagenet_model)

# define the grid search parameters
epochs = [10,25,50,100]
dense_nodes = [16,32,64,128]
dropout = [0.1,0.5,0.7]
lr = [1e-5,1e-4,1e-3]

param_grid = dict(epochs=epochs)
grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, cv=5,verbose=1, scoring = binary_accuracy,pre_dispatch=2)
grid_result = grid.fit(X, Y)

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

"""Sklearn's gridsearch has isssues with keras classifiers on multilabel classification : returns nan scoring

## Hyper-parameter optimization with keras-tuner
"""

!pip install -U keras-tuner

from tensorflow import keras
from tensorflow.keras import layers
from kerastuner.tuners import RandomSearch, Hyperband
from tensorflow.keras.applications import VGG16
from tensorflow.keras import Model
from tensorflow.keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

decays = [10,25,50,100]
dense_nodes = [16,32,64,128]
dropout = [0.1,0.5,0.7]
lrs = [1e-5,1e-4,1e-3]
models = [VGG16]

def tuner_model(hp):
  base_model = VGG16
  baseModel = base_model(weights="imagenet", include_top=False,
		input_tensor=Input(shape=(224, 224, 3)))

  for layer in baseModel.layers:
    layer.trainable = False

  headModel = baseModel.output
  headModel = AveragePooling2D(pool_size=(4, 4))(headModel)
  headModel = Flatten(name="flatten")(headModel)
  headModel = Dense(hp.Choice('dense_nodes', values=dense_nodes), activation="relu")(headModel)
  headModel = Dropout(hp.Choice('dropout_rate',values=dropout))(headModel)
  headModel = Dense(2, activation="softmax")(headModel)
  model = Model(inputs=baseModel.input, outputs=headModel)
  lr = hp.Choice('learning_rate',values=lrs)
  opt = Adam(lr=lr, decay=lr / hp.Choice('decay', values=decays))
  model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
  return model

X,Y = next(imagenet_gen)
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

tuner = Hyperband(
    tuner_model,
    objective='val_categorical_accuracy',
    max_epochs=40,
    project_name='tuning_categorical'
    )

tuner.search_space_summary()

tuner.search(trainX, trainY,epochs=25,validation_data=(testX, testY),verbose=0)
tuner.results_summary()

best_model = tuner.get_best_models(num_models=1)[0]

# Evaluate the best model.
loss, accuracy = best_model.evaluate(testX, testY)

tuner.get_best_hyperparameters()[0].values

"""Pretty good results : 0.898 vs 0.7551 categorical accuracy

## Testing different applications (ResNet, Inception)
"""

from keras.applications import VGG16
from keras import Model
from keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split

def imagenet_model(lr=1e-3, epochs=25, dropout_rate=0.5,dense_nodes=64,base_model=VGG16):
	baseModel = base_model(weights="imagenet", include_top=False,
		input_tensor=Input(shape=(224, 224, 3)))

	for layer in baseModel.layers:
		layer.trainable = False

	headModel = baseModel.output
	headModel = AveragePooling2D(pool_size=(4, 4))(headModel)
	headModel = Flatten(name="flatten")(headModel)
	headModel = Dense(dense_nodes, activation="relu")(headModel)
	headModel = Dropout(dropout_rate)(headModel)
	headModel = Dense(2, activation="softmax")(headModel)
	model = Model(inputs=baseModel.input, outputs=headModel)
	opt = Adam(lr=lr, decay=INIT_LR / epochs)
	model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])
	return model

"""Resnet : issue with overfitting"""

from keras.applications import VGG16
from keras.applications.mobilenet_v2 import MobileNetV2
from keras.applications.inception_resnet_v2 import InceptionResNetV2
from keras.applications.vgg19 import VGG19
from keras.applications.resnet import ResNet50, ResNet101
models = [ResNet50, ResNet101]
histories = []
X,Y = next(imagenet_gen)
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)
for mod in models:
	#different model
	model = imagenet_model(base_model=mod)
	#train
	H = model.fit(
		trainX, trainY,
		validation_data=(testX, testY),
		epochs=EPOCHS,
		verbose=0)
	histories.append(H)

X,Y = next(imagenet_gen)
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

from keras.layers import GlobalAveragePooling2D
import tensorflow.keras.backend as K

baseModel = ResNet50(weights="imagenet", include_top=False,
input_tensor=Input(shape=(224, 224, 3)),layers=tf.keras.layers)

for layer in model.layers:
    if hasattr(layer, 'moving_mean') and hasattr(layer, 'moving_variance'):
        layer.trainable = True
        K.eval(K.update(layer.moving_mean, K.zeros_like(layer.moving_mean)))
        K.eval(K.update(layer.moving_variance, K.ones_like(layer.moving_variance)))
    else:
        layer.trainable = False

headModel = baseModel.output
headModel = AveragePooling2D()(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(2, activation="softmax")(headModel)
model = Model(inputs=baseModel.input, outputs=headModel)
opt = Adam(lr=1e-5, decay=INIT_LR / EPOCHS)
model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])

train_datagen = ImageDataGenerator(preprocessing_function=keras.applications.resnet50.preprocess_input)

H = model.fit_generator(
		train_datagen.flow(trainX, trainY, batch_size=BS),
		validation_data=(testX, testY),
		epochs=EPOCHS)

print([x.history['val_accuracy'][-1] for x in histories])

"""## Different types of transfer learning (keeping some fully connected layers) and comparison (TODO : GRADCAM ON THESE)
Everything done on the VGG16 : our baseline model
"""

vgg = VGG16(weights="imagenet", include_top=False,	input_tensor=Input(shape=(224, 224, 3)))
[x.name for x in vgg.layers]

from keras.applications import VGG16
from sklearn.model_selection import train_test_split
vgg = VGG16(weights="imagenet", include_top=True,	input_tensor=Input(shape=(224, 224, 3)))



[x.name for x in vgg.layers]

"""### Keeping some fully connected layers without training them"""

from keras.applications import VGG16
from keras import Model
from keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from keras.optimizers import Adam
models = []
baseModel = VGG16(weights="imagenet", include_top=True,	input_tensor=Input(shape=(224, 224, 3)))

for layer in baseModel.layers:
	layer.trainable = False

for i in np.arange(4)+1:
	headModel = baseModel.layers[-i].output
	headModel = Dropout(0.5)(headModel)
	headModel = Dense(2, activation="softmax")(headModel)
	model = Model(inputs=baseModel.input, outputs=headModel)
	opt = Adam(lr=1e-3, decay=INIT_LR / EPOCHS)
	model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
	models.append(model)

losses, accs = [], []
for model in models:	
	model.fit(
	trainX, trainY,
  validation_data=(testX, testY),
	epochs=EPOCHS, verbose=0)
	loss, acc = model.evaluate(testX,testY)
	losses.append(loss)
	accs.append(acc)
accs

plt.bar(['3','2', '1', '0'],[0.53,0.73,0.77,0.91])
plt.ylabel('Accuracy')
plt.xlabel('Number of fully connected layers kept')

"""### Keeping some fully connected layers and training them"""

from keras.applications import VGG16
from keras import activations
from keras import Model
from keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from keras.optimizers import Adam
models = []
baseModel = VGG16(weights="imagenet", include_top=True,	input_tensor=Input(shape=(224, 224, 3)))
for layer in baseModel.layers:
	layer.trainable = False
baseModel.layers[-1].activation = activations.relu
for j in range(1,5):
	baseModel.layers[-j].trainable = True


for i in range(1,5):
	opt = Adam(lr=1e-3, decay=INIT_LR / EPOCHS)
	baseModel.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
	headModel = baseModel.layers[-i].output
	headModel = Dropout(0.5)(headModel)
	headModel = Dense(2, activation="softmax")(headModel)
	model = Model(inputs=baseModel.input, outputs=headModel)
	model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
	models.append(model)

import keras.backend as K
K.clear_session()

from sklearn.model_selection import train_test_split
X,Y = next(imagenet_gen)
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

losses, accs = [], []
for model in models:	
	model.fit(
	trainX, trainY,
  validation_data=(testX, testY),
	epochs=EPOCHS, verbose=0)
	loss, acc = model.evaluate(testX,testY)
	losses.append(loss)
	accs.append(acc)
accs

plt.bar(['3','2', '1', '0'],accs)
plt.ylabel('Accuracy')
plt.xlabel('Number of fully connected layers kept')

"""### Discarding fully connected layers and training some convolutional layers"""

from keras.applications import VGG16
from keras import activations
from keras import Model
from keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from keras.optimizers import Adam
models = []
layers = ['block5','block4','block3','block2','block1']

for i in range(len(layers)):
	baseModel = VGG16(weights="imagenet", include_top=False,	input_tensor=Input(shape=(224, 224, 3)))
	for layer in baseModel.layers:
		if(layer.name in layers[:i+1]):
			layer.trainable = True
		else:
			layer.trainable = False
	opt = Adam(lr=1e-3, decay=INIT_LR / EPOCHS)
	baseModel.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
	headModel = baseModel.output
	headModel = Flatten()(headModel)
	headModel = Dropout(0.5)(headModel)
	headModel = Dense(2, activation="softmax")(headModel)
	model = Model(inputs=baseModel.input, outputs=headModel)
	model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
	models.append(model)

from sklearn.model_selection import train_test_split
X,Y = next(imagenet_gen)
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)

losses, accs = [], []
for model in models:	
	model.fit(
	trainX, trainY,
  validation_data=(testX, testY),
	epochs=EPOCHS, verbose=0)
	loss, acc = model.evaluate(testX,testY)
	losses.append(loss)
	accs.append(acc)
accs

labels = [str(x) for x in range(1,6)]
plt.bar(labels,accs)
plt.ylabel('Accuracy')
plt.xlabel('Number of trainable convolutional layers')

"""## Verifying accuracy of cropping and filling up blanks in images"""

covids['Image Index'] = covids['Image Index'].apply(lambda x : x.replace('Covid','Filled'))

filled = all_xray_df.append(covids)
filled = filled.sample(frac=1).reset_index(drop=True)

covids['Image Index'] = covids['Image Index'].apply(lambda x : x.replace('Filled','Cropped'))

cropped = all_xray_df.append(covids)
cropped = cropped.sample(frac=1).reset_index(drop=True)

covids['Image Index'] = covids['Image Index'].apply(lambda x : x.replace('Cropped','Covid'))

noncropped = all_xray_df.append(covids)
noncropped = noncropped.sample(frac=1).reset_index(drop=True)

IMAGENET_SIZE = (224, 224)
filled_gen = core_idg.flow_from_dataframe(dataframe=filled,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=IMAGENET_SIZE,
                                     class_mode='categorical',
                                     batch_size=200)

cropped_gen = core_idg.flow_from_dataframe(dataframe=cropped,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=IMAGENET_SIZE,
                                     class_mode='categorical',
                                     batch_size=200)
noncropped_gen = core_idg.flow_from_dataframe(dataframe=noncropped,
                                     x_col = 'Image Index',
                                     y_col = 'Finding Labels',
                                     target_size=IMAGENET_SIZE,
                                     class_mode='categorical',
                                     batch_size=200)

from keras.applications import VGG16
from keras import Model
from keras.layers import AveragePooling2D, Input, Flatten, Dense, Dropout
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split

losses,accs=[],[]

for gen in [filled_gen,cropped_gen,noncropped_gen]:
	X,Y = next(gen)
	trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)
	baseModel = VGG16(weights="imagenet", include_top=True,	input_tensor=Input(shape=(224, 224, 3)))

	for layer in baseModel.layers:
		layer.trainable = False

	headModel = baseModel.layers[-4].output
	headModel = Dropout(0.5)(headModel)
	headModel = Dense(2, activation="softmax")(headModel)
	model = Model(inputs=baseModel.input, outputs=headModel)
	opt = Adam(lr=1e-3, decay=INIT_LR / EPOCHS)
	model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])
	model.fit(
	trainX, trainY,
  validation_data=(testX, testY),
	epochs=EPOCHS, verbose=0)
	loss, acc = model.evaluate(testX,testY)
	losses.append(loss)
	accs.append(acc)

print(losses,accs)

plt.bar(['Cropping + Filling', 'Cropping', 'No modification'],accs)
plt.ylabel('Validation accuracy')

"""Using a noncovid only validation set"""

X,Y = next(imagenet_gen)
trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.25)
baseModel = VGG16(weights="imagenet", include_top=True,	input_tensor=Input(shape=(224, 224, 3)))

for layer in baseModel.layers:
  layer.trainable = False

headModel = baseModel.layers[-4].output
headModel = Dropout(0.5)(headModel)
headModel = Dense(2, activation="softmax")(headModel)
model = Model(inputs=baseModel.input, outputs=headModel)
opt = Adam(lr=1e-3, decay=INIT_LR / EPOCHS)
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["categorical_accuracy"])

model.fit(
trainX, trainY,
validation_data=(testX, testY),
epochs=EPOCHS, verbose=0)

testx,testy = next(noncovid_gen)
loss, acc = model.evaluate(testX,testY)
print(loss,acc)

"""# Validating Results using Grad-CAM"""

!mkdir /content/Images/Gradcams

import cv2
from keras import backend as K

def get_class_activation_map(model,files,outpath='/content/Images/Gradcams') :
    for imgName in files:
      img = cv2.imread(imgName)
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      img = cv2.resize(img, (224, 224))
      img = np.expand_dims(img,axis=0)
      
      predict = model.predict(img)
      target_class = np.argmax(predict[0])
      last_conv = model.get_layer('block5_conv3')
      grads = K.gradients(model.output[:,target_class],last_conv.output)[0]
      pooled_grads = K.mean(grads,axis=(0,1,2))
      iterate = K.function([model.input],[pooled_grads,last_conv.output[0]])
      pooled_grads_value,conv_layer_output = iterate([img])
      
      for i in range(512):
          conv_layer_output[:,:,i] *= pooled_grads_value[i]
      
      heatmap = np.mean(conv_layer_output,axis=-1)
      
      for x in range(heatmap.shape[0]):
          for y in range(heatmap.shape[1]):
              heatmap[x,y] = np.max(heatmap[x,y],0)
      heatmap = np.maximum(heatmap,0)
      heatmap /= np.max(heatmap)
      plt.imshow(heatmap)
      img_gray = cv2.cvtColor(img[0], cv2.COLOR_BGR2GRAY)
      upsample = cv2.resize(heatmap, (224,224))
    
      output_path_gradcam =  outpath + '/'+ imgName.split('/')[-1]
      plt.imsave(output_path_gradcam,upsample * img_gray)

test = covids['Image Index'].to_numpy()
get_class_activation_map(model,test)

!mkdir /content/Images/noncovidcams
test = all_xray_df['Image Index'].to_numpy()
get_class_activation_map(model,test,outpath='/content/Images/noncovidcams' )

!zip -r /content/noncovid.zip /content/Images/noncovidcams